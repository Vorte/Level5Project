{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def error_rate(a, b):\n",
    "    msd = Levenshtein.distance(a,b)\n",
    "    \n",
    "    return 100.0*msd/max(len(a), len(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast, dataIO, common_functions\n",
    "from sklearn import cross_validation, linear_model, preprocessing, svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "reload(dataIO)\n",
    "reload(common_functions)\n",
    "\n",
    "def learn_offset(points, targets):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(points, targets)\n",
    "    \n",
    "    return regr\n",
    "                \n",
    "userId = 8\n",
    "keys = postures.keys()\n",
    "locations = []\n",
    "bod = []\n",
    "targets_x = []\n",
    "targets_y = []\n",
    "y = []\n",
    "touch_centers = []\n",
    "\n",
    "posture = 0\n",
    "for key in keys:\n",
    "    filenos = postures[key]\n",
    "    if key == \"two_hand\":\n",
    "        a, b, c, d, e, f = dataIO.process_twohand(userId, posture)\n",
    "        posture += 2\n",
    "    else:\n",
    "        a, b, c, d, e, f = dataIO.process_posture(userId, filenos, posture)\n",
    "        posture += 1\n",
    "    \n",
    "    locations += a\n",
    "    bod += b\n",
    "    targets_x += c \n",
    "    targets_y += d \n",
    "    y += e\n",
    "    touch_centers += f\n",
    "\n",
    "locations = np.array(locations)\n",
    "bod = np.array(bod)\n",
    "targets_x = np.array(targets_x)\n",
    "targets_y = np.array(targets_y)\n",
    "y = np.array(y)\n",
    "touch_centers = np.array(touch_centers)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(bod)  \n",
    "bod_scaled = scaler.transform(bod)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1, 0.1 ,1e-2, 1e-3, 1e-4],\n",
    "                     'C': [0.001, 0.01, 0.1 ,1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [0.001, 0.01, 0.1 ,1, 10, 100, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(C=1, cache_size=500), tuned_parameters)\n",
    "#clf = svm.SVC(C=100, kernel='rbf', gamma=0.01, cache_size=500)\n",
    "clf.fit(bod_scaled, y)\n",
    "\n",
    "regr_x = []\n",
    "regr_y = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    index = np.where(y==i)[0]\n",
    "    regr_x.append(learn_offset(locations[index], targets_x[index]))\n",
    "    regr_y.append(learn_offset(locations[index], targets_y[index]))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "new_points = []\n",
    "for i in range(len(points_test)):\n",
    "\n",
    "    point = points_test[i]\n",
    "    bod_data = scaler.transform(bod_test[i])\n",
    "    pred = clf.predict(bod_data)\n",
    "\n",
    "    pred_x = regr_x[pred].predict(point)\n",
    "    pred_y = regr_y[pred].predict(point)\n",
    "\n",
    "    new_points.append([point[0]+pred_x, point[1]+pred_y])\n",
    "\n",
    "\n",
    "new_points = np.array(new_points).T\n",
    "centers_test = centers_test.T\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
