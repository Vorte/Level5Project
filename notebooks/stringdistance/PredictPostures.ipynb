{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Levenshtein, ast, dataIO\n",
    "from sklearn import cross_validation, linear_model, preprocessing, svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "reload(dataIO)\n",
    "\n",
    "def error_rate(a, b):\n",
    "    msd = Levenshtein.distance(a,b)\n",
    "    \n",
    "    return 100.0*msd/max(len(a), len(b))\n",
    "\n",
    "def learn_offset(points, targets):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(points, targets)\n",
    "    \n",
    "    return regr\n",
    "\n",
    "\n",
    "postures = {\"left_hand\":[\"4\", \"8\", \"11\"], \"right_hand\":[\"1\", \"7\", \"10\"], \n",
    "            \"index_finger\":[\"3\", \"5\", \"12\"], \"two_hand\":[\"2\", \"6\", \"9\"]}\n",
    "                \n",
    "userId = 4\n",
    "\n",
    "def run(userId):\n",
    "    keys = postures.keys()\n",
    "    locations = []\n",
    "    bod = []\n",
    "    targets_x = []\n",
    "    targets_y = []\n",
    "    y = []\n",
    "    touch_centers = []\n",
    "\n",
    "    posture = 0\n",
    "    for key in keys:\n",
    "        filenos = postures[key]\n",
    "        if key == \"two_hand\":\n",
    "            a, b, c, d, e, f = dataIO.process_twohand(userId, posture)\n",
    "            posture += 2\n",
    "        else:\n",
    "            a, b, c, d, e, f = dataIO.process_posture(userId, filenos, posture)\n",
    "            posture += 1\n",
    "\n",
    "        locations += a\n",
    "        bod += b\n",
    "        targets_x += c \n",
    "        targets_y += d \n",
    "        y += e\n",
    "        touch_centers += f\n",
    "\n",
    "    locations = np.array(locations)\n",
    "    bod = np.array(bod)\n",
    "    targets_x = np.array(targets_x)\n",
    "    targets_y = np.array(targets_y)\n",
    "    y = np.array(y)\n",
    "    touch_centers = np.array(touch_centers)\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(bod)  \n",
    "    bod_scaled = scaler.transform(bod)\n",
    "\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1, 0.1 ,1e-2, 1e-3, 1e-4],\n",
    "                         'C': [0.001, 0.01, 0.1 ,1, 10, 100, 1000]},\n",
    "                        {'kernel': ['linear'], 'C': [0.001, 0.01, 0.1 ,1, 10, 100, 1000]}]\n",
    "\n",
    "    clf = GridSearchCV(svm.SVC(C=1, cache_size=500), tuned_parameters)\n",
    "    #clf = svm.SVC(C=100, kernel='rbf', gamma=0.01, cache_size=500)\n",
    "    clf.fit(bod_scaled, y)\n",
    "\n",
    "    regr_x = [] \n",
    "    regr_y = []\n",
    "\n",
    "    for i in range(0,5):\n",
    "        index = np.where(y==i)[0]\n",
    "        regr_x.append(learn_offset(locations[index], targets_x[index]))\n",
    "        regr_y.append(learn_offset(locations[index], targets_y[index]))\n",
    "\n",
    "    with open(\"/home/dimitar/Desktop/Python/Level5Project/Loggingapp/dataset.txt\") as f:\n",
    "        pool = f.read().splitlines()\n",
    "\n",
    "    req_sentences = []\n",
    "    typed_sentences = []\n",
    "    pred_sentences = []\n",
    "\n",
    "    for i in range(13, 25):\n",
    "        column_index = 0\n",
    "        if i in [15, 17, 21]:\n",
    "            column_index = 1\n",
    "\n",
    "        with open(\"/home/dimitar/Desktop/Python/experiment/results/\"\n",
    "                   +str(userId)+\"_\"+str(i)+\"up.txt\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "            touches = map(lambda x: x.split('\\t'), lines[1:])\n",
    "\n",
    "        req_string = ''.join(np.array(touches)[:,column_index]) \n",
    "        locations = np.array(map(lambda x: ast.literal_eval(x),\n",
    "                                np.array(touches)[:,(column_index+2)]))\n",
    "        bod = np.array(map(lambda x: ast.literal_eval(x),\n",
    "                                np.array(touches)[:,(column_index+4)]))\n",
    "\n",
    "        for sentence in pool: \n",
    "            index = req_string.find(sentence)\n",
    "            if index!=-1:\n",
    "                req_sentences.append(sentence)\n",
    "                typed_locations = np.array(locations[index:index+len(sentence)])\n",
    "                typed_bod = np.array(bod[index:index+len(sentence)])\n",
    "\n",
    "                bod_data = scaler.transform(typed_bod)\n",
    "                pred = clf.predict(bod_data)\n",
    "\n",
    "                pred_x = []\n",
    "                pred_y = []\n",
    "                for i in range(len(sentence)):\n",
    "                    regr_no = pred[i]\n",
    "                    pred_x.append(regr_x[regr_no].predict(typed_locations[i]))\n",
    "                    pred_y.append(regr_y[regr_no].predict(typed_locations[i]))\n",
    "\n",
    "                new_points = typed_locations + np.dstack((pred_x, pred_y))[0]\n",
    "                typed_sentences.append(dataIO.typed_string(typed_locations))\n",
    "                pred_sentences.append(dataIO.typed_string(new_points))\n",
    "\n",
    "\n",
    "    error_typed = []\n",
    "    error_pred = []\n",
    "    for i in range(len(req_sentences)):    \n",
    "        req_sentence = req_sentences[i]\n",
    "        typed_sentence = typed_sentences[i]\n",
    "        pred_sentence = pred_sentences[i]\n",
    "        error_typed.append(error_rate(req_sentence, typed_sentence))\n",
    "        error_pred.append(error_rate(req_sentence, pred_sentence))\n",
    "\n",
    "    print\n",
    "    print (\"Mean error rate before: %.2f %%\"% np.mean(np.array(error_typed)))\n",
    "    print (\"Mean error rate after: %.2f %%\"% np.mean(np.array(error_pred)))\n",
    "    \n",
    "    return np.mean(np.array(error_typed)), np.mean(np.array(error_pred))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean error rate before: 38.97 %\n",
      "Mean error rate after: 37.14 %\n",
      "\n",
      "Mean error rate before: 32.04 %\n",
      "Mean error rate after: 23.38 %\n",
      "\n",
      "Mean error rate before: 33.64 %\n",
      "Mean error rate after: 35.09 %\n",
      "\n",
      "Mean error rate before: 19.54 %\n",
      "Mean error rate after: 19.34 %\n",
      "\n",
      "Mean error rate before: 21.21 %\n",
      "Mean error rate after: 23.06 %\n",
      "\n",
      "Mean error rate before: 21.59 %\n",
      "Mean error rate after: 13.89 %\n",
      "\n",
      "Mean error rate before: 30.33 %\n",
      "Mean error rate after: 31.47 %\n",
      "\n",
      "Mean error rate before: 22.99 %\n",
      "Mean error rate after: 17.60 %\n",
      "\n",
      "Mean error rate before: 15.82 %\n",
      "Mean error rate after: 17.51 %\n",
      "\n",
      "Mean error rate before: 33.58 %\n",
      "Mean error rate after: 24.29 %\n",
      "\n",
      "Mean error rate before: 28.91 %\n",
      "Mean error rate after: 26.31 %\n",
      "\n",
      "Mean error rate before: 36.02 %\n",
      "Mean error rate after: 23.33 %\n",
      "\n",
      "Mean error rate before: 35.58 %\n",
      "Mean error rate after: 27.00 %\n",
      "\n",
      "Mean error rate before: 23.64 %\n",
      "Mean error rate after: 22.57 %\n",
      "\n",
      "Mean error rate before: 39.89 %\n",
      "Mean error rate after: 28.13 %\n",
      "[-1.8351317474221887, -8.65756501194846, 1.4534098027475437, -0.20380982067430864, 1.8498889071581317, -7.6993460909002636, 1.1362692324463488, -5.3872730518148018, 1.6873928635300288, -9.2900665963379332, -2.6001699581173021, -12.682896276777921, -8.5798078480718338, -1.0668083588215964, -11.75811294756727]\n"
     ]
    }
   ],
   "source": [
    "error_diff = []\n",
    "for i in range(3, 18):\n",
    "    typed, pred = run(i)\n",
    "    error_diff.append(pred-typed)\n",
    "    \n",
    "print error_diff    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.24226846017\n"
     ]
    }
   ],
   "source": [
    "print np.mean(np.array(error_diff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
