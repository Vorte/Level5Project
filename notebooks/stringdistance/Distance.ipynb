{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def error_rate(a, b):\n",
    "    msd = Levenshtein.distance(a,b)\n",
    "    \n",
    "    return 100.0*msd/max(len(a), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean error rate before: 23.07 %\n",
      "Mean error rate after: 98.70 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import dataIO\n",
    "reload(dataIO)\n",
    "\n",
    "with open(\"/home/dimitar/Desktop/Python/Level5Project/Loggingapp/dataset.txt\") as f:\n",
    "    pool = f.read().splitlines()\n",
    "\n",
    "#def read(userId):\n",
    "req_sentences = []\n",
    "typed_sentences = []\n",
    "\n",
    "for i in range(13, 25):\n",
    "#for i in [15, 17, 21]:\n",
    "    column_index = 0\n",
    "    if i in [15, 17, 21]:\n",
    "        column_index = 1\n",
    "\n",
    "    with open(\"/home/dimitar/Desktop/Python/experiment/results/3\"\n",
    "               +\"_\"+str(i)+\"up.txt\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "        touches = map(lambda x: x.split('\\t'), lines[1:])\n",
    "\n",
    "    req_string = ''.join(np.array(touches)[:,column_index]) \n",
    "    locations = map(lambda x: ast.literal_eval(x),\n",
    "                            np.array(touches)[:,(column_index+2)])\n",
    "    \n",
    "    for sentence in pool: \n",
    "        index = req_string.find(sentence)\n",
    "        if index!=-1:\n",
    "            req_sentences.append(sentence)\n",
    "            typed_locations = locations[index:index+len(sentence)]\n",
    "            typed_sentences.append(dataIO.typed_string(typed_locations))\n",
    "        \n",
    "#    return req_sentences, typed_sentences, req_string\n",
    "\n",
    "#req_sentences, typed_sentences, req_string = read(11)\n",
    "error = []\n",
    "for i in range(len(req_sentences)):    \n",
    "    req_sentence = req_sentences[i]\n",
    "    typed_sentence = typed_sentences[i]\n",
    "    error.append(error_rate(req_sentence, typed_sentence))\n",
    "\n",
    "print\n",
    "print (\"Mean error rate before: %.2f %%\"% np.mean(np.array(error)))\n",
    "\n",
    "new_locations = run(3, locations)\n",
    "typed_sentences = []\n",
    "index = 0\n",
    "for sentence in req_sentences: \n",
    "    typed_locations = new_locations[index:index+len(sentence)]\n",
    "    #print typed_locations\n",
    "    typed_sentences.append(dataIO.typed_string(typed_locations))\n",
    "    index += len(sentence)\n",
    "                \n",
    "#print req_sentences        \n",
    "#print typed_sentences        \n",
    "\n",
    "error = []\n",
    "for i in range(len(req_sentences)):    \n",
    "    req_sentence = req_sentences[i]\n",
    "    typed_sentence = typed_sentences[i]\n",
    "    error.append(error_rate(req_sentence, typed_sentence))\n",
    "\n",
    "print (\"Mean error rate after: %.2f %%\" % np.mean(np.array(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataIO\n",
    "from sklearn import cross_validation, linear_model\n",
    "reload(dataIO)\n",
    "\n",
    "def learn_offset(points, targets):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(points, targets)\n",
    "    \n",
    "    return regr\n",
    "\n",
    "def run(userId, touches):\n",
    "    locations, bod, targets_x, targets_y, y, touch_centers = dataIO.process_twohand(userId)\n",
    "\n",
    "    locations = np.array(locations)\n",
    "    targets_x = np.array(targets_x)\n",
    "    targets_y = np.array(targets_y)\n",
    "\n",
    "    regr_x = learn_offset(locations, targets_x)\n",
    "    regr_y = learn_offset(locations, targets_y)\n",
    "\n",
    "    new_points = []\n",
    "    for i in range(len(touches)):\n",
    "        point = touches[i]\n",
    "\n",
    "        pred_x = regr_x.predict(point)\n",
    "        pred_y = regr_y.predict(point)\n",
    "\n",
    "        new_points.append([point[0]+pred_x, point[1]+pred_y])\n",
    "\n",
    "    return np.array(new_points)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "considering whatcan you wait until mondaythanks for your concernis stan looking for a go no go decisiondo you know anythingspoke with gregthanks for askingi would hope costs would be lower on future additions\n",
      "nothing for paigedavis had not yet updated the model for thisthey are specifically concerned about the current intercompany notescan you handlestill not resolvedhow did you make sure it was the right seti think we should consider this requestmostly a social call\n",
      "capital for red rock between two thousand one and two thousand twoi think we should put a number on the tableboth of us are still herewe need a copy of whatever they are looking atthis will be harddid you not read my first emailget with david lunddo you and george have a thing going\n",
      "24\n",
      "\n",
      "Mean error rate before: 19.11 %\n",
      "Mean error rate before: 14.29 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import dataIO\n",
    "reload(dataIO)\n",
    "\n",
    "userId = 17\n",
    "locations, bod, targets_x, targets_y, y, touch_centers = dataIO.process_twohand(userId)\n",
    "\n",
    "locations = np.array(locations)\n",
    "targets_x = np.array(targets_x)\n",
    "targets_y = np.array(targets_y)\n",
    "\n",
    "regr_x = learn_offset(locations, targets_x)\n",
    "regr_y = learn_offset(locations, targets_y)\n",
    "\n",
    "with open(\"/home/dimitar/Desktop/Python/Level5Project/Loggingapp/dataset.txt\") as f:\n",
    "    pool = f.read().splitlines()\n",
    "\n",
    "#def read(userId):\n",
    "req_sentences = []\n",
    "typed_sentences = []\n",
    "pred_sentences = []\n",
    "#for i in range(13, 25):\n",
    "for i in [15, 17, 21]:\n",
    "    column_index = 0\n",
    "    if i in [15, 17, 21]:\n",
    "        column_index = 1\n",
    "\n",
    "    with open(\"/home/dimitar/Desktop/Python/experiment/results/\"\n",
    "               +str(userId)+\"_\"+str(i)+\"up.txt\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "        touches = map(lambda x: x.split('\\t'), lines[1:])\n",
    "\n",
    "    req_string = ''.join(np.array(touches)[:,column_index]) \n",
    "    locations = map(lambda x: list(ast.literal_eval(x)),\n",
    "                            np.array(touches)[:,(column_index+2)])\n",
    "   \n",
    "    print req_string\n",
    "    for sentence in pool: \n",
    "        index = req_string.find(sentence)\n",
    "        if index!=-1:\n",
    "            req_sentences.append(sentence)\n",
    "            typed_locations = np.array(locations[index:index+len(sentence)])\n",
    "            \n",
    "            pred_x = regr_x.predict(typed_locations)\n",
    "            pred_y = regr_y.predict(typed_locations)\n",
    "            pred = typed_locations + np.dstack((pred_x, pred_y))[0]\n",
    "            \n",
    "            typed_sentences.append(dataIO.typed_string(typed_locations))\n",
    "            pred_sentences.append(dataIO.typed_string(pred))\n",
    "            \n",
    "error_typed = []\n",
    "error_pred = []\n",
    "for i in range(len(req_sentences)):    \n",
    "    req_sentence = req_sentences[i]\n",
    "    typed_sentence = typed_sentences[i]\n",
    "    pred_sentence = pred_sentences[i]\n",
    "    error_typed.append(error_rate(req_sentence, typed_sentence))\n",
    "    error_pred.append(error_rate(req_sentence, pred_sentence))\n",
    "\n",
    "print\n",
    "print (\"Mean error rate before: %.2f %%\"% np.mean(np.array(error_typed)))\n",
    "print (\"Mean error rate before: %.2f %%\"% np.mean(np.array(error_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
