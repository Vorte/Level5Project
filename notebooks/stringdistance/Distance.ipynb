{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def error_rate(a, b):\n",
    "    msd = Levenshtein.distance(a,b)\n",
    "    \n",
    "    return 100.0*msd/max(len(a), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataIO\n",
    "from sklearn import cross_validation, linear_model\n",
    "reload(dataIO)\n",
    "\n",
    "def learn_offset(points, targets):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(points, targets)\n",
    "    \n",
    "    return regr\n",
    "\n",
    "def run(userId, touches):\n",
    "    locations, bod, targets_x, targets_y, y, touch_centers = dataIO.process_twohand(userId)\n",
    "\n",
    "    locations = np.array(locations)\n",
    "    targets_x = np.array(targets_x)\n",
    "    targets_y = np.array(targets_y)\n",
    "\n",
    "    regr_x = learn_offset(locations, targets_x)\n",
    "    regr_y = learn_offset(locations, targets_y)\n",
    "\n",
    "    new_points = []\n",
    "    for i in range(len(touches)):\n",
    "        point = touches[i]\n",
    "\n",
    "        pred_x = regr_x.predict(point)\n",
    "        pred_y = regr_y.predict(point)\n",
    "\n",
    "        new_points.append([point[0]+pred_x, point[1]+pred_y])\n",
    "\n",
    "    return np.array(new_points)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean error rate before: 5.91 %\n",
      "Mean error rate after: 7.85 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import dataIO\n",
    "reload(dataIO)\n",
    "\n",
    "userId = 11\n",
    "locations, bod, targets_x, targets_y, y, touch_centers = dataIO.process_twohand(userId)\n",
    "\n",
    "locations = np.array(locations)\n",
    "targets_x = np.array(targets_x)\n",
    "targets_y = np.array(targets_y)\n",
    "\n",
    "regr_x = learn_offset(locations, targets_x)\n",
    "regr_y = learn_offset(locations, targets_y)\n",
    "\n",
    "with open(\"/home/dimitar/Desktop/Python/Level5Project/Loggingapp/dataset.txt\") as f:\n",
    "    pool = f.read().splitlines()\n",
    "\n",
    "#def read(userId):\n",
    "req_sentences = []\n",
    "typed_sentences = []\n",
    "pred_sentences = []\n",
    "#for i in range(13, 25):\n",
    "for i in [15, 17, 21]:\n",
    "    column_index = 0\n",
    "    if i in [15, 17, 21]:\n",
    "        column_index = 1\n",
    "\n",
    "    with open(\"/home/dimitar/Desktop/Python/experiment/results/\"\n",
    "               +str(userId)+\"_\"+str(i)+\"up.txt\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "        touches = map(lambda x: x.split('\\t'), lines[1:])\n",
    "\n",
    "    req_string = ''.join(np.array(touches)[:,column_index]) \n",
    "    locations = map(lambda x: list(ast.literal_eval(x)),\n",
    "                            np.array(touches)[:,(column_index+2)])\n",
    "   \n",
    "    for sentence in pool: \n",
    "        index = req_string.find(sentence)\n",
    "        if index!=-1:\n",
    "            req_sentences.append(sentence)\n",
    "            typed_locations = np.array(locations[index:index+len(sentence)])\n",
    "            \n",
    "            pred_x = regr_x.predict(typed_locations)\n",
    "            pred_y = regr_y.predict(typed_locations)\n",
    "            pred = typed_locations + np.dstack((pred_x, pred_y))[0]\n",
    "            \n",
    "            typed_sentences.append(dataIO.typed_string(typed_locations))\n",
    "            pred_sentences.append(dataIO.typed_string(pred))\n",
    "\n",
    "error_typed = []\n",
    "error_pred = []\n",
    "for i in range(len(req_sentences)):    \n",
    "    req_sentence = req_sentences[i]\n",
    "    typed_sentence = typed_sentences[i]\n",
    "    pred_sentence = pred_sentences[i]\n",
    "    error_typed.append(error_rate(req_sentence, typed_sentence))\n",
    "    error_pred.append(error_rate(req_sentence, pred_sentence))\n",
    "\n",
    "print\n",
    "print (\"Mean error rate before: %.2f %%\"% np.mean(np.array(error_typed)))\n",
    "print (\"Mean error rate after: %.2f %%\"% np.mean(np.array(error_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
