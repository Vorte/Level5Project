{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Levenshtein, ast, dataIO, VBGP\n",
    "from sklearn import cross_validation, linear_model, preprocessing, utils\n",
    "reload(dataIO)\n",
    "\n",
    "def error_rate(a, b):\n",
    "    msd = Levenshtein.distance(a,b)\n",
    "    \n",
    "    return 100.0*msd/max(len(a), len(b))\n",
    "\n",
    "def learn_offset(points, targets):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(points, targets)\n",
    "    \n",
    "    return regr\n",
    "\n",
    "\n",
    "postures = {\"left_hand\":[\"4\", \"8\", \"11\"], \"right_hand\":[\"1\", \"7\", \"10\"], \n",
    "            \"index_finger\":[\"3\", \"5\", \"12\"], \"two_hand\":[\"2\", \"6\", \"9\"]}\n",
    "                \n",
    "userId = 4\n",
    "\n",
    "keys = postures.keys()\n",
    "locations = []\n",
    "bod = []\n",
    "targets_x = []\n",
    "targets_y = []\n",
    "y = []\n",
    "\n",
    "posture = 0\n",
    "for key in keys:\n",
    "    filenos = postures[key]\n",
    "    if key == \"two_hand\":\n",
    "        a, b, c, d, e, f = dataIO.process_twohand(userId, posture)\n",
    "        posture += 2\n",
    "    else:\n",
    "        a, b, c, d, e, f = dataIO.process_posture(userId, filenos, posture)\n",
    "        posture += 1\n",
    "\n",
    "    locations += a\n",
    "    bod += b\n",
    "    targets_x += c \n",
    "    targets_y += d \n",
    "    y += e\n",
    "\n",
    "locations = np.array(locations)\n",
    "bod = np.array(bod)\n",
    "targets_x = np.array(targets_x)\n",
    "targets_y = np.array(targets_y)\n",
    "y = np.array(y)\n",
    "\n",
    "locations, bod, targets_x, targets_y, y = utils.shuffle(locations, bod, targets_x, targets_y, y)\n",
    "locations = np.concatenate((locations, locations**2),1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(bod)  \n",
    "bod_scaled = scaler.transform(bod)\n",
    "\n",
    "thetas = np.array([[1 for x in range(24)], [0.1 for x in range(24)], [0.01 for x in range(24)],\n",
    "     [0.001 for x in range(24)],[10 for x in range(24)]])\n",
    "\n",
    "gp = VBGP.VBGP()\n",
    "gp.fit(bod_scaled, y, thetas[0], nos_its=50, thresh=0.1)\n",
    "gp.optimize(thetas, nos_its=50, thresh=0.1)\n",
    "\n",
    "print (\"Best gamma: %.3f\" %gp.Theta[0][0])\n",
    "\n",
    "regr_x = [] \n",
    "regr_y = []\n",
    "\n",
    "for i in range(5):\n",
    "    index = np.where(y==i)[0]\n",
    "    regr_x.append(learn_offset(locations[index], targets_x[index]))\n",
    "    regr_y.append(learn_offset(locations[index], targets_y[index])) \n",
    "\n",
    "with open(\"../../Loggingapp/dataset.txt\") as f:\n",
    "    pool = f.read().splitlines()\n",
    "\n",
    "pool = sorted(pool, key=len, reverse=True)\n",
    "\n",
    "req_sentences = []\n",
    "typed_phys = []\n",
    "pred_phys = []\n",
    "typed_virtual=[]\n",
    "pred_virtual = []\n",
    "\n",
    "for i in range(13, 25):\n",
    "    column_index = 0\n",
    "    if i in [15, 17, 21]:\n",
    "        column_index = 1\n",
    "\n",
    "    with open(\"../../data/\"+str(userId)+\"_\"+str(i)+\"up.txt\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "        touches = map(lambda x: x.split('\\t'), lines[1:])\n",
    "\n",
    "    touches = np.array(touches)\n",
    "    locations = []\n",
    "    req_string = ''\n",
    "    bods = []\n",
    "\n",
    "    for touch in touches:\n",
    "        req_string = req_string + ''.join(touch[column_index]) \n",
    "        bod = dataIO.createlist(touch[column_index+4])\n",
    "\n",
    "        if dataIO.contains_spikes(bod):\n",
    "            continue\n",
    "\n",
    "        bods.append(bod)\n",
    "        locations.append(ast.literal_eval(touch[column_index+2]))\n",
    "\n",
    "    bods = np.array(bods)\n",
    "    locations=np.array(locations)\n",
    "\n",
    "    for sentence in pool:\n",
    "        if len(req_string)==0:\n",
    "            break\n",
    "\n",
    "        index = req_string.find(sentence)\n",
    "        if index!=-1:\n",
    "            req_sentences.append(sentence)\n",
    "            typed_locations = np.array(locations[index:index+len(sentence)])\n",
    "            typed_bod = np.array(bods[index:index+len(sentence)])\n",
    "\n",
    "            req_string = req_string[:index]+req_string[index+len(sentence):]\n",
    "            locations = np.delete(locations, np.s_[index:index+len(sentence)], 0)\n",
    "            bods = np.delete(bods, np.s_[index:index+len(sentence)], 0)\n",
    "\n",
    "            bod_data = scaler.transform(typed_bod)\n",
    "            pred = gp.predict(bod_data)\n",
    "            pred = np.argmax(pred, axis=1)\n",
    "            vectors = np.concatenate((typed_locations, typed_locations **2),1)\n",
    "\n",
    "            pred_x = np.zeros(len(vectors))\n",
    "            pred_y = np.zeros(len(vectors))\n",
    "            for i in range(len(vectors)):\n",
    "                regr_no = pred[i]\n",
    "                pred_x[i] = regr_x[regr_no].predict(vectors[i])\n",
    "                pred_y[i] = regr_y[regr_no].predict(vectors[i])\n",
    "\n",
    "            new_points = typed_locations + np.dstack((pred_x, pred_y))[0]\n",
    "            typed_virtual.append(dataIO.typed_virt(typed_locations))\n",
    "            pred_virtual.append(dataIO.typed_virt(new_points))\n",
    "            \n",
    "            typed_phys.append(dataIO.typed_phys(typed_locations))\n",
    "            pred_phys.append(dataIO.typed_phys(new_points))\n",
    "\n",
    "error_typed = np.zeros((len(req_sentences), 7))\n",
    "error_pred = np.zeros((len(req_sentences), 7))\n",
    "phys_typed = np.zeros(len(req_sentences))\n",
    "phys_pred = np.zeros(len(req_sentences))\n",
    "for i in range(len(req_sentences)):    \n",
    "    req_sentence = req_sentences[i]\n",
    "    for j in range(7):\n",
    "        typed_sentence = typed_virtual[i][j]\n",
    "        pred_sentence = pred_virtual[i][j]\n",
    "        error_typed[i][j] = error_rate(req_sentence, typed_sentence)\n",
    "        error_pred[i][j] = error_rate(req_sentence, pred_sentence)\n",
    "    \n",
    "    phys_typed[i] = error_rate(req_sentence, typed_phys[i])\n",
    "    phys_pred[i] = error_rate(req_sentence, pred_phys[i])\n",
    "\n",
    "print\n",
    "print (\"Physical button error rate before model: %.2f%%\" %np.mean(phys_typed))    \n",
    "print (\"Physical button error rate after model: %.2f%%\" %np.mean(phys_pred))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b50ac3266b66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mbefore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_typed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mafter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9c0d6e890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "before = np.mean(error_typed, 0)\n",
    "after = np.mean(error_pred, 0)\n",
    "\n",
    "plt.errorbar(range(1,8), after, marker=\"o\", label = \"predictSVM\")\n",
    "plt.errorbar(range(1,8), before, linestyle=\"--\", marker=\"o\", label=\"no model\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('virtual button size in mm')\n",
    "plt.ylabel('MSD error rate %')\n",
    "#plt.savefig('/home/dimitar/Desktop/Latex/L5Project/mpaper/img/pred_post13.png', bbox_inches='tight', dpi=400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
