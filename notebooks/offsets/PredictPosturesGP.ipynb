{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on x before regression: 305.11\n",
      "MSE on y before regression: 128.41\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d5492c9d72cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mgp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVBGP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVBGP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbod_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnos_its\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnos_its\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dimitar/Desktop/Python/Level5Project/notebooks/offsets/VBGP/VBGP.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, thetas, cv, nos_its, thresh)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mfold_gp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVBGP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mfold_gp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnos_its\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfold_gp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dimitar/Desktop/Python/Level5Project/notebooks/offsets/VBGP/VBGP.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, t, theta, nos_its, thresh)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__fit_gp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnos_its\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dimitar/Desktop/Python/Level5Project/notebooks/offsets/VBGP/VBGP.py\u001b[0m in \u001b[0;36m__fit_gp\u001b[1;34m(self, nos_its, thresh)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mlower_bound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnos_samps_tg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mlower_bound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlower_bound\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msafelogsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dimitar/Desktop/Python/Level5Project/notebooks/offsets/VBGP/tmean.pyc\u001b[0m in \u001b[0;36mtmean\u001b[1;34m(m, index_max, n_samps)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         nr = np.mean(safenormpdf(u.conj().T + m[index_max] \n\u001b[1;32m---> 22\u001b[1;33m                                  - m[r])*np.prod(safenormcdf(sr.conj().T), 0))\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mindex_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dimitar/Desktop/Python/Level5Project/notebooks/offsets/VBGP/tmean.pyc\u001b[0m in \u001b[0;36msafenormcdf\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnormcdfM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormcdfM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msafenormpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dimitar/Desktop/Python/Level5Project/notebooks/offsets/VBGP/normcdfM.pyc\u001b[0m in \u001b[0;36mnormcdfM\u001b[1;34m(x, m, s)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0merfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast, dataIO, common_functions\n",
    "from VBGP import VBGP\n",
    "from sklearn import cross_validation, linear_model, preprocessing, svm\n",
    "reload(dataIO)\n",
    "reload(common_functions)\n",
    "\n",
    "postures = {\"left_hand\":[\"4\", \"8\", \"11\"], \"right_hand\":[\"1\", \"7\", \"10\"], \n",
    "            \"index_finger\":[\"3\", \"5\", \"12\"], \"two_hand\":[\"2\", \"6\", \"9\"]}\n",
    "\n",
    "locations = []\n",
    "bod = []\n",
    "targets_x = []\n",
    "targets_y = []\n",
    "y = []\n",
    "touch_centers = []\n",
    "\n",
    "def learn_offset(points, targets):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(points, targets)\n",
    "    \n",
    "    return regr\n",
    "\n",
    "def process_twohand(userid, filenos, posture):\n",
    "    \n",
    "    centers = dataIO.get_key_centers()\n",
    "    \n",
    "    for fileno in filenos:\n",
    "        filename = \"/home/dimitar/Desktop/Python/experiment/results/\"+str(userid)+\"_\"+fileno+\"up.txt\"\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "            lines = map(lambda x: x.split('\\t'), lines[1:])\n",
    "            for line in lines:\n",
    "                letter = line[1]\n",
    "                location = list(ast.literal_eval(line[3]))\n",
    "                center = centers[letter]\n",
    "                \n",
    "                if not dataIO.iscorrect(location, center):\n",
    "                    continue\n",
    "                \n",
    "                if line[0] == \"left\":\n",
    "                    y.append(posture)\n",
    "                else:\n",
    "                    y.append(posture+1)\n",
    "                \n",
    "                touch_centers.append(center)\n",
    "                targets_x.append(center[0]-location[0])\n",
    "                targets_y.append(center[1]-location[1])                \n",
    "                locations.append(location)\n",
    "                bod.append(dataIO.createlist(line[-1]))\n",
    "    \n",
    "\n",
    "def process_posture(userid, filenos, posture): \n",
    "    \n",
    "    centers = dataIO.get_key_centers()\n",
    "    \n",
    "    for fileno in filenos:\n",
    "        filename = \"/home/dimitar/Desktop/Python/experiment/results/\"+str(userid)+\"_\"+fileno+\"up.txt\"\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "            lines = map(lambda x: x.split('\\t'), lines[1:])\n",
    "            for line in lines:\n",
    "                letter = line[0]\n",
    "                location = list(ast.literal_eval(line[2]))\n",
    "                center = centers[letter]\n",
    "                \n",
    "                if not dataIO.iscorrect(location, center):\n",
    "                    continue\n",
    "                \n",
    "                targets_x.append(center[0]-location[0])\n",
    "                targets_y.append(center[1]-location[1])                \n",
    "                touch_centers.append(center)\n",
    "                locations.append(location)\n",
    "                bod.append(dataIO.createlist(line[-1]))\n",
    "                y.append(posture)\n",
    "                \n",
    "\n",
    "def read_data(userid):    \n",
    "    keys = postures.keys()\n",
    "    \n",
    "    posture = 0\n",
    "    for key in keys:\n",
    "        filenos = postures[key]\n",
    "        if key == \"two_hand\":\n",
    "            process_twohand(userid, filenos, posture)\n",
    "            posture += 2\n",
    "        else:\n",
    "            process_posture(userid, filenos, posture)\n",
    "            posture += 1\n",
    "\n",
    "read_data(8)\n",
    "\n",
    "locations = np.array(locations)\n",
    "bod = np.array(bod)\n",
    "targets_x = np.array(targets_x)\n",
    "targets_y = np.array(targets_y)\n",
    "y = np.array(y)\n",
    "touch_centers = np.array(touch_centers)\n",
    "\n",
    "print(\"MSE on x before regression: %.2f\"  % np.mean(targets_x ** 2))\n",
    "print(\"MSE on y before regression: %.2f\"  % np.mean(targets_y ** 2))\n",
    "within_before = common_functions.circle_button_error(locations, touch_centers)\n",
    "\n",
    "thetas = np.array([[1 for x in range(24)], [0.1 for x in range(24)], [0.01 for x in range(24)],\n",
    "         [0.001 for x in range(24)],[0.0001 for x in range(24)]])\n",
    "\n",
    "foldno = 1\n",
    "se_x = []\n",
    "se_y = []\n",
    "within_after = []\n",
    "kf = cross_validation.KFold(len(y), n_folds=10, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf: \n",
    "    print foldno\n",
    "    points_train, points_test = locations[train_index], locations[test_index]\n",
    "    bod_train, bod_test = bod[train_index], bod[test_index]\n",
    "    t_x_train, t_x_test = targets_x[train_index], targets_x[test_index]\n",
    "    t_y_train, t_y_test = targets_y[train_index], targets_y[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    centers_train, centers_test = touch_centers[train_index], touch_centers[test_index]\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(bod_train)  \n",
    "    bod_scaled = scaler.transform(bod_train)\n",
    "    test = scaler.transform(bod_test)\n",
    "    \n",
    "    gp = VBGP.VBGP()\n",
    "    gp.fit(bod_scaled, y_train, theta=thetas[0], nos_its = 50, thresh = 0.1)\n",
    "    gp.optimize(thetas, nos_its = 50, thresh = 0.1)\n",
    "    \n",
    "    probabilities = gp.predict(test)    \n",
    "    pred = np.argmax(probabilities, axis=1)\n",
    "#     pred_r = pred.reshape(pred.shape[0])\n",
    "\n",
    "#     error = pred_r - y_test\n",
    "#     print y_test.shape\n",
    "#     print np.nonzero(error)[0].shape\n",
    "    \n",
    "    #clf = svm.SVC(C=100, kernel='rbf', gamma=0.01, cache_size=500)\n",
    "    #clf.fit(bod_scaled, y_train)\n",
    "    \n",
    "    regr_x = []\n",
    "    regr_y = []\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        index = np.where(y_train==i)[0]\n",
    "        regr_x.append(learn_offset(points_train[index], t_x_train[index]))\n",
    "        regr_y.append(learn_offset(points_train[index], t_y_train[index]))\n",
    "        \n",
    "    new_points = []\n",
    "    for i in range(len(points_test)):        \n",
    "        point = points_test[i]\n",
    "        \n",
    "        pred_x = regr_x[pred[i]].predict(point)\n",
    "        pred_y = regr_y[pred[i]].predict(point)\n",
    "        \n",
    "        new_points.append([point[0]+pred_x, point[1]+pred_y])\n",
    "     \n",
    "    within_after.append(common_functions.circle_button_error(new_points, centers_test))\n",
    "    new_points = np.array(new_points).T\n",
    "    centers_test = centers_test.T\n",
    "    \n",
    "    se_x.append((new_points[0]-centers_test[0])**2)\n",
    "    se_y.append((new_points[1]-centers_test[1])**2)\n",
    "    \n",
    "#     foldno +=1    \n",
    "\n",
    "se_x = np.array([item for sublist in se_x for item in sublist])\n",
    "se_y = np.array([item for sublist in se_y for item in sublist])\n",
    "\n",
    "print \n",
    "print(\"Mean MSE on x: %.2f\" % np.mean(se_x))\n",
    "print(\"Mean MSE on y: %.2f\" % np.mean(se_y))      \n",
    "within_after = np.mean(np.array(within_after), 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
