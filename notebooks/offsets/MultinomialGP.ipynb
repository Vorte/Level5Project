{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.94771063e-06   9.90030296e-01   9.86937379e-03   5.95542608e-08\n",
      "    7.37611133e-05   1.85614682e-05]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.randint(5, size=(6, 100))\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "clf =  MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "\n",
    "test = X[0]\n",
    "test[1] = 0\n",
    "test = np.random.randint(5, size=(100))\n",
    "\n",
    "print(clf.predict_proba(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### normcdf\n",
    "import numpy as np\n",
    "from scipy.special import erfc\n",
    "import math\n",
    "\n",
    "def normcdfM(x, m=None, s=None):\n",
    "    if m==None and s==None:\n",
    "        z = x\n",
    "    elif s==None:\n",
    "        z = x-m\n",
    "    else:\n",
    "        z = (x-m)/s\n",
    "        \n",
    "    return 0.5*erfc(-z/math.sqrt(2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### normpdf\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def normpdfM(x, m=0, s=1):    \n",
    "    o = 1.0/math.sqrt(2.0*math.pi*(s**2))\n",
    "    \n",
    "    return o*math.exp((-((x-m)**2)/(2*(s**2)))[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##tmean\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def tmean(m, index_max, n_samps):\n",
    "    \n",
    "    K = m.shape[0]\n",
    "    u = np.random.randn(n_samps,1)\n",
    "\n",
    "    t = m[index_max]*np.ones((K, 1)) - m \n",
    "    tr = t\n",
    "    t = np.delete(t, index_max, 0)\n",
    "    \n",
    "    s = np.tile(u, (1, K-1)) + np.tile(t,(1, n_samps)).conj().T\n",
    "    z = np.mean(np.prod(safenormcdf(s.conj().T), 0))\n",
    "\n",
    "    tm = np.zeros(m.shape[0])\n",
    "    for r in range(0, K):\n",
    "        sr = np.tile(u, (1, K)) + np.tile(tr, (1, n_samps)).conj().T\n",
    "        sr.take([r, index_max], axis=1)\n",
    "        \n",
    "        nr = np.mean(safenormpdf(u.conj().T + m[index_max] \n",
    "                                 - m[r])*np.prod(safenormcdf(sr.conj().T), 0))\n",
    "        \n",
    "        if r == index_max:\n",
    "            tm[r] = 0.0\n",
    "        else:\n",
    "            tm[r] = m[r] - nr/z\n",
    "            \n",
    "    tm[index_max] = np.sum(m, axis=0) - np.sum(tm, axis=0)\n",
    "    tm = tm.conj().T                    \n",
    "            \n",
    "    return tm, z\n",
    "                                                               \n",
    "\n",
    "def safenormcdf(x):\n",
    "    #x = x[0]\n",
    "    thresh=-10;\n",
    "    x[np.nonzero(x<thresh)] = thresh\n",
    "    return normcdfM(x)\n",
    "\n",
    "def safenormpdf(x):\n",
    "    x=x[0]\n",
    "    thresh=35;\n",
    "    x[np.nonzero(x<-thresh)] = -thresh\n",
    "    x[np.nonzero(x>thresh)] = thresh\n",
    "    return normpdfM(x)\n",
    "\n",
    "def safelogsc(x):\n",
    "    if x<1e-300:\n",
    "        x = 1e-200\n",
    "    elif x>1e300:\n",
    "        x = 1e300\n",
    "    return math.log(x)\n",
    "\n",
    "def safelog(x):\n",
    "    x[np.nonzero(x<1e-300)] = 1e-200\n",
    "    x[np.nonzero(x>1e300)] = 1e300\n",
    "    return math.log(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(n):\n",
    "\n",
    "    u = 4*np.random.rand(n,2)-2    \n",
    "    \n",
    "    i = np.nonzero( (u[:,0]**2 + u[:,1]**2 > 0.1) & (u[:,0]**2 + u[:,1]**2 < 0.5) )\n",
    "    j = np.nonzero( (u[:,0]**2 + u[:,1]**2 > .6) & (u[:,0]**2 + u[:,1]**2 < 1) )\n",
    "    X = u[np.concatenate((i[0],j[0])),:]\n",
    "\n",
    "    t = np.zeros((i[0].shape[0],1), dtype=int)\n",
    "    t = np.concatenate((t, np.ones((j[0].shape[0],1), dtype=int)))\n",
    "    x = 0.1*np.random.randn(i[0].shape[0],2)\n",
    "    \n",
    "    k = np.nonzero(x[:,0]**2 + x[:,1]**2 < 0.1)\n",
    "    X = np.concatenate((X, x[k[0],:]))\n",
    "    t = np.concatenate((t, 2*np.ones((k[0].shape[0],1), dtype=int)))\n",
    "    X = np.concatenate((X, np.random.randn(X.shape[0],8)), 1)\n",
    "\n",
    "    \n",
    "    return X, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080,)\n",
      "(27,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def dist(X,Y,Z): # X, Y, Z matrices\n",
    "    \n",
    "    nx = X.shape[0]\n",
    "    ny = Y.shape[0]\n",
    "    \n",
    "#     distance= (np.sum(np.dot((X**2), Z), 1)*np.ones(ny)+\n",
    "#               np.ones((nx,1))*(np.sum(np.dot((Y**2), Z), 1).conj().T) \n",
    "#                - 2*(np.dot(np.dot(X, Z), Y.conj().T))) \n",
    "\n",
    "    distance= (np.sum(np.dot((X**2), Z), 1).reshape(nx,1)*np.ones(ny)+\n",
    "              np.ones((nx,1))*(np.sum(np.dot((Y**2), Z), 1).conj().T) \n",
    "               - 2*(np.dot(np.dot(X, Z), Y.conj().T))) \n",
    "           \n",
    "    return distance\n",
    "\n",
    "\n",
    "def VarMultProbRegGP(X, t, X_test=0, t_test=0, theta=0, theta_estimate=0, \n",
    "                     nos_its=0, kernel_Type=0, poly_kernel_power=0, thresh=0):\n",
    "    \n",
    "    start = time.time()*1000\n",
    "    SMALL_NOS = 1e-10\n",
    "\n",
    "    nos_samps_tg = 1000\n",
    "\n",
    "    nos_samps_is = 1000\n",
    "\n",
    "    sigma = 1e-6\n",
    "\n",
    "    tau = 1e-6\n",
    "\n",
    "    C = np.unique(t).size\n",
    "    N, D = X.shape\n",
    "    Y = np.random.randn(N, C)\n",
    "    M = np.random.rand(N, C)\n",
    "    beta = theta\n",
    "    Theta = np.diag(theta)\n",
    "\n",
    "    psi = np.ones((1, theta.size)) \n",
    "    In = np.eye(N)\n",
    "    Ic = np.eye(C)\n",
    "\n",
    "    diff = 1e100\n",
    "    its = 0\n",
    "\n",
    "    K = np.exp(-dist(X,X,Theta)) + np.eye(N)*SMALL_NOS; # TODO: implement create kernel function\n",
    "    \n",
    "    iK = np.linalg.inv(K+In)\n",
    "    Ki = np.dot(K, iK)\n",
    "    \n",
    "    #THETA = []\n",
    "    LOWER_BOUND = [-1e-3]\n",
    "    #PL = []\n",
    "    constant = (-0.5*C*np.trace(np.dot(K, iK))\n",
    "                -0.5*C*np.trace(iK)\n",
    "                -0.5*C*safelogsc(abs(np.linalg.det(K)))\n",
    "                +0.5*C*safelogsc(abs(np.linalg.det(np.dot(K, iK))))\n",
    "                -0.5*N*C*safelogsc(2*math.pi)\n",
    "                +0.5*N*C + 0.5*N*safelogsc(2*math.pi))\n",
    "    \n",
    "    test_err = []\n",
    "    while its<nos_its and diff>thresh:\n",
    "        its += 1\n",
    "        \n",
    "        for k in range(0, C):\n",
    "            M[:,[k]] = np.dot(Ki, Y[:,[k]])\n",
    "  \n",
    "        #print (\"started Y %d\"%(time.time()*1000-start))\n",
    "        lower_bound = 0    \n",
    "        for n in range(0, N):\n",
    "            a, z = tmean(M[[n],].conj().T, t[n], nos_samps_tg)\n",
    "            Y[n] = a\n",
    "            lower_bound = lower_bound + safelogsc(z)\n",
    "            \n",
    "        #print (\"completed Y %d\"%(time.time()*1000-start))\n",
    "        \n",
    "        if its == 2: \n",
    "             LOWER_BOUND[0] = LOWER_BOUND[1] #### WHY? \n",
    "        \n",
    "#         lower_bound = (lower_bound-0.5*C*np.trace(np.dot(K, iK))\n",
    "#                                   -0.5*np.sum(np.diag(np.dot(np.dot(M.conj().T, iK), M)))\n",
    "#                                   -0.5*C*np.trace(iK)\n",
    "#                                   -0.5*C*safelogsc(abs(np.linalg.det(K)))\n",
    "#                                   +0.5*C*safelogsc(abs(np.linalg.det(np.dot(K, iK))))\n",
    "#                                   -0.5*N*C*safelogsc(2*math.pi)\n",
    "#                                   +0.5*N*C + 0.5*N*safelogsc(2*math.pi))\n",
    "\n",
    "        lower_bound = (lower_bound + constant -0.5*np.sum(np.diag(np.dot(np.dot(M.conj().T, iK), M))))\n",
    "        \n",
    "        LOWER_BOUND.append([lower_bound]) \n",
    "        if its == 2: \n",
    "             LOWER_BOUND[0] = LOWER_BOUND[1]                                            \n",
    "                                                    \n",
    "        diff = abs(100*(lower_bound - LOWER_BOUND[-2])/LOWER_BOUND[-2])\n",
    "        #print (\"completed iteration %d\"%(time.time()*1000-start))\n",
    "        \n",
    "    ####### predict ########\n",
    "\n",
    "    n_test = X_test.shape[0]\n",
    "    K_test = np.exp(-dist(X,X_test,Theta))\n",
    "    K_test_self = np.exp(-dist(X_test,X_test,Theta))\n",
    "\n",
    "    S = (np.diag(K_test_self) - np.diag(np.dot(np.dot(K_test.conj().T, iK), K_test))).conj().T\n",
    "\n",
    "    predictive_likelihood = 0\n",
    "    res = (np.dot(np.dot(Y.conj().T, iK), K_test)).conj().T\n",
    "    P_test = np.ones((n_test, C))\n",
    "    u = np.random.randn(nos_samps_tg, 1)\n",
    "\n",
    "    for n in range(0, n_test):\n",
    "        for i in range(0, C):\n",
    "            pp = np.ones((nos_samps_tg, 1))\n",
    "            for j in range(0, C):\n",
    "                if j!=i:\n",
    "                    pp = pp*safenormcdf(u+(res[n,i]-res[n,j])/(math.sqrt(1+S[n])))\n",
    "\n",
    "            P_test[n,i] = np.mean(pp)\n",
    "        P_test[n] = P_test[n]/np.sum(P_test[n])\n",
    "\n",
    "        #predictive_likelihood = predictive_likelihood + safelog(P_test[n, t_test[n]])\n",
    "        \n",
    "    #print (\"completed prediction %d\"%(time.time()*1000-start))\n",
    "    return P_test\n",
    "        \n",
    "    \n",
    "# X_1 = np.random.rand(20, 5)\n",
    "# X_2 = 100*np.random.rand(20,5)\n",
    "# X = np.concatenate((X_1, X_2))\n",
    "# X_test = np.random.rand(50,5)\n",
    "# y = np.array([0 for x in range(0, 20)]+[1 for x in range(0, 20)])\n",
    "# theta = np.random.rand(5)\n",
    "\n",
    "# X = np.array([[0.0, 0.0], [1.0, 1.0],[2.0, 2.0]])\n",
    "# t = np.array([0, 1, 2]) #starting from 0\n",
    "# X_t = np.array([[0.0, 0.0], [1.0, 1.0], [2.0, 2.0]])\n",
    "# theta = np.array([0.169, 0.334])\n",
    "\n",
    "X, t = generate(500)\n",
    "X_t, t_t = generate(5000)\n",
    "theta = np.array([1.1348e+01, 8.8135e+00, 1.7372e-03, 2.2966e-03, 1.7476e-03, \n",
    "                  1.6263e-03, 1.8975e-03, 1.2296e-03,  2.4512e-03, 1.6161e-03])\n",
    "\n",
    "prob = VarMultProbRegGP(X, t, theta=theta, nos_its=50, thresh = 0.1, X_test=X_t)    \n",
    "pred = np.argmax(prob, axis=1)\n",
    "pred = pred.reshape(pred.shape[0])\n",
    "t_t = t_t.reshape(t_t.shape[0])\n",
    "\n",
    "error = pred - t_t\n",
    "print t_t.shape\n",
    "print np.nonzero(error)[0].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on x before regression: 305.11\n",
      "MSE on y before regression: 128.41\n",
      "(156,)\n",
      "(20,)\n",
      "(156,)\n",
      "(27,)\n",
      "(156,)\n",
      "(22,)\n",
      "(155,)\n",
      "(18,)\n",
      "(155,)\n",
      "(32,)\n",
      "\n",
      "Mean MSE on x: 75.08\n",
      "Mean MSE on y: 117.36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast, dataIO, common_functions\n",
    "from sklearn import cross_validation, linear_model, preprocessing, svm\n",
    "reload(dataIO)\n",
    "reload(common_functions)\n",
    "\n",
    "postures = {\"left_hand\":[\"4\", \"8\", \"11\"], \"right_hand\":[\"1\", \"7\", \"10\"], \n",
    "            \"index_finger\":[\"3\", \"5\", \"12\"], \"two_hand\":[\"2\", \"6\", \"9\"]}\n",
    "\n",
    "locations = []\n",
    "bod = []\n",
    "targets_x = []\n",
    "targets_y = []\n",
    "y = []\n",
    "touch_centers = []\n",
    "\n",
    "def learn_offset(points, targets):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(points, targets)\n",
    "    \n",
    "    return regr\n",
    "\n",
    "def process_twohand(userid, filenos, posture):\n",
    "    \n",
    "    centers = dataIO.get_key_centers()\n",
    "    \n",
    "    for fileno in filenos:\n",
    "        filename = \"/home/dimitar/Desktop/Python/experiment/results/\"+str(userid)+\"_\"+fileno+\"up.txt\"\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "            lines = map(lambda x: x.split('\\t'), lines[1:])\n",
    "            for line in lines:\n",
    "                letter = line[1]\n",
    "                location = list(ast.literal_eval(line[3]))\n",
    "                center = centers[letter]\n",
    "                \n",
    "                if not dataIO.iscorrect(location, center):\n",
    "                    continue\n",
    "                \n",
    "                if line[0] == \"left\":\n",
    "                    y.append(posture)\n",
    "                else:\n",
    "                    y.append(posture+1)\n",
    "                \n",
    "                touch_centers.append(center)\n",
    "                targets_x.append(center[0]-location[0])\n",
    "                targets_y.append(center[1]-location[1])                \n",
    "                locations.append(location)\n",
    "                bod.append(dataIO.createlist(line[-1]))\n",
    "    \n",
    "\n",
    "def process_posture(userid, filenos, posture): \n",
    "    \n",
    "    centers = dataIO.get_key_centers()\n",
    "    \n",
    "    for fileno in filenos:\n",
    "        filename = \"/home/dimitar/Desktop/Python/experiment/results/\"+str(userid)+\"_\"+fileno+\"up.txt\"\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "            lines = map(lambda x: x.split('\\t'), lines[1:])\n",
    "            for line in lines:\n",
    "                letter = line[0]\n",
    "                location = list(ast.literal_eval(line[2]))\n",
    "                center = centers[letter]\n",
    "                \n",
    "                if not dataIO.iscorrect(location, center):\n",
    "                    continue\n",
    "                \n",
    "                targets_x.append(center[0]-location[0])\n",
    "                targets_y.append(center[1]-location[1])                \n",
    "                touch_centers.append(center)\n",
    "                locations.append(location)\n",
    "                bod.append(dataIO.createlist(line[-1]))\n",
    "                y.append(posture)\n",
    "                \n",
    "\n",
    "def read_data(userid):    \n",
    "    keys = postures.keys()\n",
    "    \n",
    "    posture = 0\n",
    "    for key in keys:\n",
    "        filenos = postures[key]\n",
    "        if key == \"two_hand\":\n",
    "            process_twohand(userid, filenos, posture)\n",
    "            posture += 2\n",
    "        else:\n",
    "            process_posture(userid, filenos, posture)\n",
    "            posture += 1\n",
    "\n",
    "read_data(8)\n",
    "\n",
    "locations = np.array(locations)\n",
    "bod = np.array(bod)\n",
    "targets_x = np.array(targets_x)\n",
    "targets_y = np.array(targets_y)\n",
    "y = np.array(y)\n",
    "touch_centers = np.array(touch_centers)\n",
    "\n",
    "print(\"MSE on x before regression: %.2f\"  % np.mean(targets_x ** 2))\n",
    "print(\"MSE on y before regression: %.2f\"  % np.mean(targets_y ** 2))\n",
    "within_before = common_functions.circle_button_error(locations, touch_centers)\n",
    "\n",
    "foldno = 1\n",
    "se_x = []\n",
    "se_y = []\n",
    "within_after = []\n",
    "kf = cross_validation.KFold(len(y), n_folds=5, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf:    \n",
    "    points_train, points_test = locations[train_index], locations[test_index]\n",
    "    bod_train, bod_test = bod[train_index], bod[test_index]\n",
    "    t_x_train, t_x_test = targets_x[train_index], targets_x[test_index]\n",
    "    t_y_train, t_y_test = targets_y[train_index], targets_y[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    centers_train, centers_test = touch_centers[train_index], touch_centers[test_index]\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(bod_train)  \n",
    "    bod_scaled = scaler.transform(bod_train)\n",
    "    test = scaler.transform(bod_test)\n",
    "    \n",
    "    theta = np.array([0.01 for x in range(0, 24)])\n",
    "    prob = VarMultProbRegGP(bod_scaled, y_train, theta=theta, nos_its=50, thresh = 0.1, X_test=test)\n",
    "    \n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    pred_r = pred.reshape(pred.shape[0])\n",
    "\n",
    "    error = pred_r - y_test\n",
    "    print y_test.shape\n",
    "    print np.nonzero(error)[0].shape\n",
    "    \n",
    "    #clf = svm.SVC(C=100, kernel='rbf', gamma=0.01, cache_size=500)\n",
    "    #clf.fit(bod_scaled, y_train)\n",
    "    \n",
    "    regr_x = []\n",
    "    regr_y = []\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        index = np.where(y_train==i)[0]\n",
    "        regr_x.append(learn_offset(points_train[index], t_x_train[index]))\n",
    "        regr_y.append(learn_offset(points_train[index], t_y_train[index]))\n",
    "        \n",
    "    new_points = []\n",
    "    for i in range(len(points_test)):        \n",
    "        point = points_test[i]\n",
    "        \n",
    "        pred_x = regr_x[pred[i]].predict(point)\n",
    "        pred_y = regr_y[pred[i]].predict(point)\n",
    "        \n",
    "        new_points.append([point[0]+pred_x, point[1]+pred_y])\n",
    "     \n",
    "    within_after.append(common_functions.circle_button_error(new_points, centers_test))\n",
    "    new_points = np.array(new_points).T\n",
    "    centers_test = centers_test.T\n",
    "    \n",
    "    se_x.append((new_points[0]-centers_test[0])**2)\n",
    "    se_y.append((new_points[1]-centers_test[1])**2)\n",
    "    \n",
    "#     foldno +=1    \n",
    "\n",
    "se_x = np.array([item for sublist in se_x for item in sublist])\n",
    "se_y = np.array([item for sublist in se_y for item in sublist])\n",
    "\n",
    "print \n",
    "print(\"Mean MSE on x: %.2f\" % np.mean(se_x))\n",
    "print(\"Mean MSE on y: %.2f\" % np.mean(se_y))      \n",
    "within_after = np.mean(np.array(within_after), 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
