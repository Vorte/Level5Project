{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import ast, dataIO, random\n",
      "from sklearn import linear_model, preprocessing, svm\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "%matplotlib inline\n",
      "reload(dataIO)\n",
      "\n",
      "def get_touch_locations(userid):\n",
      "    touches = []\n",
      "    filenos = [\"2\", \"6\", \"9\"]\n",
      "    \n",
      "    for fileno in filenos:\n",
      "        filename = \"/home/dimitar/Desktop/Python/experiment/results/\"+str(userid)+\"_\"+fileno+\"up.txt\"\n",
      "        with open(filename, \"r\") as f:\n",
      "            lines = f.read().splitlines()\n",
      "            lines = map(lambda x: x.split('\\t'), lines[1:])\n",
      "            for line in lines:\n",
      "                letter = line[1]\n",
      "                location = ast.literal_eval(line[3])\n",
      "                x = location[0]\n",
      "                y = location[1]\n",
      "                time = line[2]\n",
      "                bod = dataIO.createlist(line[-1])\n",
      "                if line[0] == \"left\":\n",
      "                    touch = dataIO.Touch(x,y,bod,letter,time, True)\n",
      "                else:\n",
      "                    touch = dataIO.Touch(x,y,bod,letter,time, False)\n",
      "                touches.append(touch)\n",
      "        \n",
      "    return touches\n",
      "\n",
      "locations = get_touch_locations(16)\n",
      "filtered = dataIO.filter_new(locations)\n",
      "\n",
      "centers = dataIO.get_key_centers()\n",
      "keys = centers.keys()\n",
      "\n",
      "points = []\n",
      "touches_test = []\n",
      "touch_centers = []\n",
      "left_train = []\n",
      "t_l_x_train = []\n",
      "t_l_y_train = []\n",
      "\n",
      "right_train = []\n",
      "t_r_x_train = []\n",
      "t_x_test = []\n",
      "t_r_y_train = []\n",
      "t_y_test = []\n",
      "\n",
      "bod_left_train = []\n",
      "bod_right_train = []\n",
      "\n",
      "for key in keys:\n",
      "    if key==\"SPACE\":\n",
      "        continue\n",
      "    \n",
      "    center = centers[key]\n",
      "    touches = dataIO.find_touches(filtered, key)\n",
      "    #random.seed(0) \n",
      "    random.shuffle(touches)\n",
      "    \n",
      "    count_l = 0\n",
      "    count_r = 0\n",
      "    for touch in touches:\n",
      "        touch_centers.append(center)\n",
      "        location = [touch.x, touch.y]\n",
      "        bod = touch.bod\n",
      "        points.append(location)      \n",
      "        \n",
      "        if touch.left:\n",
      "            if count_l>3:\n",
      "                touches_test.append(touch)\n",
      "                t_x_test.append(center[0]-location[0])\n",
      "                t_y_test.append(center[1]-location[1])\n",
      "            else:\n",
      "                left_train.append(location)\n",
      "                t_l_x_train.append(center[0]-location[0])\n",
      "                t_l_y_train.append(center[1]-location[1])\n",
      "                bod_left_train.append(bod)\n",
      "                count_l += 1\n",
      "        else:\n",
      "            if count_r>3:\n",
      "                touches_test.append(touch)\n",
      "                t_x_test.append(center[0]-location[0])\n",
      "                t_y_test.append(center[1]-location[1])  \n",
      "            else:\n",
      "                right_train.append(location)\n",
      "                t_r_x_train.append(center[0]-location[0])\n",
      "                t_r_y_train.append(center[1]-location[1])\n",
      "                bod_right_train.append(bod)\n",
      "                count_r += 1\n",
      "                \n",
      "bod_train = np.array(bod_left_train+bod_right_train)\n",
      "bod_y = [0 for x in range(len(bod_left_train))] + [1 for x in range(len(bod_right_train))]\n",
      "\n",
      "\n",
      "touch_centers = np.array(touch_centers)\n",
      "points = np.array(points)\n",
      "\n",
      "t_l_x_train = np.array(t_l_x_train)\n",
      "t_x_test = np.array(t_x_test)\n",
      "t_l_y_train = np.array(t_l_y_train)\n",
      "t_y_test = np.array(t_y_test)\n",
      "\n",
      "t_r_x_train = np.array(t_r_x_train)\n",
      "t_r_y_train = np.array(t_r_y_train)\n",
      "\n",
      "points_unz = np.array(map(lambda x: list(x) , zip(*points))) \n",
      "centers_unz = np.array(map(lambda x: list(x) , zip(*touch_centers)))\n",
      "\n",
      "scaler = preprocessing.StandardScaler().fit(bod_train)  \n",
      "bod_scaled = scaler.transform(bod_train)\n",
      "\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4],\n",
      "                     'C': [0.001, 0.01, 0.1 ,1, 10, 100, 1000]},\n",
      "                    {'kernel': ['linear'], 'C': [0.001, 0.01, 0.1 ,1, 10, 100, 1000]}]\n",
      "\n",
      "\n",
      "clf = GridSearchCV(svm.SVC(C=1, cache_size=500), tuned_parameters, cv=10)\n",
      "clf.fit(bod_scaled, bod_y)\n",
      "\n",
      "print(\"Best parameters set found on training set:\")\n",
      "print\n",
      "print clf.best_estimator_\n",
      "print\n",
      "\n",
      "print(\"MSE on x before regression: %.2f\"\n",
      "           % np.mean((points_unz[0] - centers_unz[0]) ** 2))\n",
      "\n",
      "print(\"MSE on y before regression: %.2f\"\n",
      "           % np.mean((points_unz[1] - centers_unz[1]) ** 2))\n",
      "print\n",
      "\n",
      "regr_l_x = linear_model.LinearRegression()\n",
      "regr_l_y = linear_model.LinearRegression()\n",
      "\n",
      "regr_l_x.fit(left_train, t_l_x_train)\n",
      "regr_l_y.fit(left_train, t_l_y_train)\n",
      "\n",
      "regr_r_x = linear_model.LinearRegression()\n",
      "regr_r_y = linear_model.LinearRegression()\n",
      "\n",
      "regr_r_x.fit(right_train, t_r_x_train)\n",
      "regr_r_y.fit(right_train, t_r_y_train)\n",
      "\n",
      "se_x = []\n",
      "se_y = []\n",
      "for i in range(len(touches_test)):\n",
      "    touch = touches_test[i]\n",
      "    \n",
      "    location = [touch.x, touch.y]\n",
      "    scaled = scaler.transform(touch.bod)\n",
      "    if clf.predict(scaled)==0:\n",
      "        se_x.append((regr_l_x.predict(location) - t_x_test[i])**2)\n",
      "        se_y.append((regr_l_y.predict(location) - t_y_test[i])**2)\n",
      "    else:\n",
      "        se_x.append((regr_r_x.predict(location) - t_x_test[i])**2)\n",
      "        se_y.append((regr_r_y.predict(location) - t_y_test[i])**2)\n",
      "\n",
      "print\n",
      "print(\"MSE on on x: %.2f\" % np.mean(np.array(se_x)))\n",
      "print(\"MSE on on y: %.2f\" % np.mean(np.array(se_y)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Filtered 2 points.\n",
        "Best parameters set found on training set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "SVC(C=100, cache_size=500, class_weight=None, coef0=0.0, degree=3, gamma=0.01,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "\n",
        "MSE on x before regression: 225.54\n",
        "MSE on y before regression: 166.06\n",
        "\n",
        "\n",
        "MSE on on x: 160.03\n",
        "MSE on on y: 178.13\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Perform CV"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import ast, dataIO\n",
      "from sklearn import cross_validation, linear_model, preprocessing, svm\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "%matplotlib inline\n",
      "reload(dataIO)\n",
      "\n",
      "def get_touch_locations(userid):\n",
      "    touches = []\n",
      "    filenos = [\"2\", \"6\", \"9\"]\n",
      "    \n",
      "    for fileno in filenos:\n",
      "        filename = \"/home/dimitar/Desktop/Python/experiment/results/\"+str(userid)+\"_\"+fileno+\"up.txt\"\n",
      "        with open(filename, \"r\") as f:\n",
      "            lines = f.read().splitlines()\n",
      "            lines = map(lambda x: x.split('\\t'), lines[1:])\n",
      "            for line in lines:\n",
      "                letter = line[1]\n",
      "                location = ast.literal_eval(line[3])\n",
      "                x = location[0]\n",
      "                y = location[1]\n",
      "                time = line[2]\n",
      "                bod = dataIO.createlist(line[-1])\n",
      "                if line[0] == \"left\":\n",
      "                    touch = dataIO.Touch(x,y,bod,letter,time, True)\n",
      "                else:\n",
      "                    touch = dataIO.Touch(x,y,bod,letter,time, False)\n",
      "                touches.append(touch)\n",
      "        \n",
      "    return touches\n",
      "\n",
      "\n",
      "locations = get_touch_locations(16)\n",
      "filtered = dataIO.filter_new(locations)\n",
      "\n",
      "centers = dataIO.get_key_centers()\n",
      "keys = centers.keys()\n",
      "\n",
      "touch_centers = []\n",
      "touches = []\n",
      "points = []\n",
      "\n",
      "points_l = []\n",
      "points_r = []\n",
      "bod_l = []\n",
      "bod_r = []\n",
      "t_l_x = []\n",
      "t_l_y = []\n",
      "t_r_x = []\n",
      "t_r_y = []\n",
      "\n",
      "for touch in filtered:\n",
      "    center = centers[touch.letter]\n",
      "    touch_centers.append(center)\n",
      "    location = [touch.x, touch.y]        \n",
      "    points.append(location)\n",
      "    \n",
      "    if touch.left:\n",
      "        #points_l.append([touch.x, touch.y, touch.x**2, touch.y**2])\n",
      "        points_l.append(location)\n",
      "        bod_l.append(touch.bod)\n",
      "        t_l_x.append(center[0]-location[0])\n",
      "        t_l_y.append(center[1]-location[1])\n",
      "    else:\n",
      "        #points_r.append([touch.x, touch.y, touch.x**2, touch.y**2])\n",
      "        points_r.append(location)\n",
      "        bod_r.append(touch.bod)\n",
      "        t_r_x.append(center[0]-location[0])\n",
      "        t_r_y.append(center[1]-location[1])\n",
      "                 \n",
      "            \n",
      "touch_centers = np.array(touch_centers)\n",
      "points = np.array(points)\n",
      "points_l = np.array(points_l)\n",
      "points_r = np.array(points_r)\n",
      "bod_l = np.array(bod_l)\n",
      "bod_r = np.array(bod_r)\n",
      "t_l_x = np.array(t_l_x)\n",
      "t_l_y = np.array(t_l_y)\n",
      "t_r_x = np.array(t_r_x)\n",
      "t_r_y = np.array(t_r_y)\n",
      "\n",
      "points_unz = np.array(map(lambda x: list(x) , zip(*points))) \n",
      "centers_unz = np.array(map(lambda x: list(x) , zip(*touch_centers)))\n",
      "\n",
      "print(\"MSE on x before regression: %.2f\"\n",
      "           % np.mean((points_unz[0] - centers_unz[0]) ** 2))\n",
      "\n",
      "print(\"MSE on y before regression: %.2f\"\n",
      "           % np.mean((points_unz[1] - centers_unz[1]) ** 2))\n",
      "print\n",
      "\n",
      "foldno = 1\n",
      "mse_x = []\n",
      "mse_y = []\n",
      "kf_l = cross_validation.KFold(len(points_l), n_folds=5, shuffle=True)\n",
      "kf_r = cross_validation.KFold(len(points_r), n_folds=5, shuffle=True)\n",
      "\n",
      "for left_index, right_index in zip(kf_l, kf_r):\n",
      "    \n",
      "    train_index_l, test_index_l = left_index[0], left_index[1]\n",
      "    train_index_r, test_index_r = right_index[0], right_index[1]\n",
      "    \n",
      "    print\n",
      "    print (\"##### Fold %d #####\" %foldno)\n",
      "    print\n",
      "    \n",
      "    left_train, left_test = points_l[train_index_l], points_l[test_index_l]    \n",
      "    t_l_x_train, t_l_x_test = t_l_x[train_index_l], t_l_x[test_index_l]\n",
      "    t_l_y_train, t_l_y_test = t_l_y[train_index_l], t_l_y[test_index_l]\n",
      "    bod_l_train, bod_l_test = bod_l[train_index_l], bod_l[test_index_l]\n",
      "    \n",
      "    right_train, right_test = points_r[train_index_r], points_r[test_index_r]    \n",
      "    t_r_x_train, t_r_x_test = t_r_x[train_index_r], t_r_x[test_index_r]\n",
      "    t_r_y_train, t_r_y_test = t_r_y[train_index_r], t_r_y[test_index_r]    \n",
      "    bod_r_train, bod_r_test = bod_r[train_index_r], bod_r[test_index_r]\n",
      "    \n",
      "    bod_train = np.concatenate((bod_l_train, bod_r_train))\n",
      "    bod_y = [0 for x in range(len(bod_l_train))] + [1 for x in range(len(bod_r_train))]\n",
      "    \n",
      "    scaler = preprocessing.StandardScaler().fit(bod_train)  \n",
      "    bod_scaled = scaler.transform(bod_train)\n",
      "    \n",
      "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4],\n",
      "                         'C': [0.001, 0.01, 0.1 ,1, 10, 100, 1000]},\n",
      "                        {'kernel': ['linear'], 'C': [0.001, 0.01, 0.1 ,1, 10, 100, 1000]}]\n",
      "    \n",
      "    clf = GridSearchCV(svm.SVC(C=1, cache_size=500), tuned_parameters)\n",
      "    clf.fit(bod_scaled, bod_y)\n",
      "    \n",
      "    print clf.best_estimator_\n",
      "    print\n",
      "\n",
      "    regr_l_x = linear_model.LinearRegression()\n",
      "    regr_l_y = linear_model.LinearRegression()\n",
      "    regr_r_x = linear_model.LinearRegression()\n",
      "    regr_r_y = linear_model.LinearRegression()     \n",
      "    \n",
      "    regr_l_x.fit(left_train, t_l_x_train)\n",
      "    regr_l_y.fit(left_train, t_l_y_train)    \n",
      "    regr_r_x.fit(right_train, t_r_x_train)\n",
      "    regr_r_y.fit(right_train, t_r_y_train)\n",
      "    \n",
      "    points_test = np.concatenate((left_test, right_test))\n",
      "    targets_x = np.concatenate((t_l_x_test, t_r_x_test))\n",
      "    targets_y = np.concatenate((t_l_y_test, t_r_y_test))\n",
      "    bod_test = np.concatenate((bod_l_test, bod_r_test))\n",
      "    \n",
      "    se_x = []\n",
      "    se_y = []\n",
      "    for i in range(len(points_test)):\n",
      "        scaled = scaler.transform(bod_test[i])\n",
      "        location = points_test[i]\n",
      "        pred = clf.predict(scaled)\n",
      "        \n",
      "        if pred == 0:\n",
      "            pred_x = regr_l_x.predict(location)\n",
      "            pred_y = regr_l_y.predict(location)\n",
      "        else:\n",
      "            pred_x = regr_r_x.predict(location)\n",
      "            pred_y = regr_r_y.predict(location)\n",
      "            \n",
      "#         if ((pred_x - targets_x[i])**2)>3500:\n",
      "#             print pred\n",
      "#             print i\n",
      "#             print location\n",
      "#             print bod_test[i]\n",
      "#             print pred_x\n",
      "#             print pred_y\n",
      "#             print targets_x[i]\n",
      "#             pred_x =  regr_l_x.predict(location)\n",
      "#             pred_y =  regr_l_y.predict(location)\n",
      "#             print ((pred_x - targets_x[i])**2)\n",
      "#             print ((pred_y - targets_y[i])**2)\n",
      "        \n",
      "#         if pred == 1 and i<len(left_test):\n",
      "#             print \"incorrect\"\n",
      "#             print (pred_x - targets_x[i])**2\n",
      "#             print (pred_y - targets_y[i])**2\n",
      "#             print location\n",
      "#             print \"#####\"\n",
      "#         elif i<len(left_test):\n",
      "#             print (pred_x - targets_x[i])**2\n",
      "#             print (pred_y - targets_y[i])**2\n",
      "#             print location\n",
      "#             print \"#####\"\n",
      "        \n",
      "        se_x.append((pred_x - targets_x[i])**2)\n",
      "        se_y.append((pred_y - targets_y[i])**2)\n",
      "        \n",
      "    mse = np.mean(np.array(se_x))\n",
      "    print(\"MSE on x: %.2f\" %mse)\n",
      "    mse_x.append(mse)\n",
      "    \n",
      "    mse = np.mean(np.array(se_y))\n",
      "    print(\"MSE on y: %.2f\" %mse)\n",
      "    mse_y.append(mse)\n",
      "    \n",
      "    foldno +=1    \n",
      "\n",
      "print \n",
      "print(\"Mean MSE on on x: %.2f\" % np.mean(mse_x))\n",
      "print(\"Mean MSE on on y: %.2f\" % np.mean(mse_y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Filtered 2 points.\n",
        "MSE on x before regression: 225.54\n",
        "MSE on y before regression: 166.06\n",
        "\n",
        "\n",
        "##### Fold 1 #####\n",
        "\n",
        "SVC(C=10, cache_size=500, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=0.0001, kernel='rbf', max_iter=-1, probability=False,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "MSE on x: 172.20\n",
        "MSE on y: 195.36\n",
        "\n",
        "##### Fold 2 #####\n",
        "\n",
        "SVC(C=1, cache_size=500, class_weight=None, coef0=0.0, degree=3, gamma=0.001,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "MSE on x: 125.33\n",
        "MSE on y: 175.38\n",
        "\n",
        "##### Fold 3 #####\n",
        "\n",
        "SVC(C=1000, cache_size=500, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=0.001, kernel='rbf', max_iter=-1, probability=False,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "MSE on x: 131.19\n",
        "MSE on y: 119.51\n",
        "\n",
        "##### Fold 4 #####\n",
        "\n",
        "SVC(C=1, cache_size=500, class_weight=None, coef0=0.0, degree=3, gamma=0.01,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "MSE on x: 78.08\n",
        "MSE on y: 219.69\n",
        "\n",
        "##### Fold 5 #####\n",
        "\n",
        "SVC(C=10, cache_size=500, class_weight=None, coef0=0.0, degree=3, gamma=0.01,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "MSE on x: 137.22\n",
        "MSE on y: 138.31\n",
        "\n",
        "Mean MSE on on x: 128.80\n",
        "Mean MSE on on y: 169.65\n"
       ]
      }
     ],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}